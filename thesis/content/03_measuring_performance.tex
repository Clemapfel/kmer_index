%\chapter{Measuring Performance}
\chapter{Measuring Performance}

% UNORDERED MAP: METHODS
\begin{minipage}{\linewidth}
\section{Unordered Map}
\subsection{Methods}
As the unordered map is the central data structure of the kmer-index choosing the best performing available
implementation contributes tremendously to the performance of the kmer-index. As C++s \lstinline{std::unorderd_map}
did not prove sufficiently performant enough the following maps implemented by 3rd parties were tested and evaluated
specifically in the context of use within the kmer-index:

\begin{itemize}
\item \lstinline{std::unordered_map} from the \href{https://en.cppreference.com/w/cpp/container/unordered_map}{C++17 standard library}
\item \lstinline{boost::unordered_map} from the \href{https://www.boost.org/doc/libs/1_65_0/doc/html/boost/unordered_map.html}{1.65.1 Boost Library}
\item \lstinline{absl::node_hash_map} from Googles \href{https://abseil.io/docs/cpp/guides/container\#abslnode_hash_map-and-abslnode_hash_set}{Abseil}
\item \lstinline{robin_hood::unordered_map} as provided by \href{https://github.com/martinus/robin-hood-hashing}{Martin Ankerl et. al.}
\end{itemize}

Each map was filled with a fixed number of randomized integers simulating both the hash and position of kmer in the
final implementation and the duration to return a specific but randomized element was measured. Only retrieval was tested
here since after construction of the kmer-index no insertions will take place during runtime.

% UNORDERED MAP: RESULTS
\subsection{Results}
\begin{figure}[H] \label{}
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/map_vs_map/map_vs_map}

\caption{Search performance for different map implementations over size of
map.}
\end{figure}
\end{minipage}

Results indicate that \lstinline{robin_hood::unordered_map} performed
best regardless of the number of elements contained and was as such
used as the central data structure for the kmer-index.

% SINGLE KMER: METHODS
\section{Single kmer-Index}
\subsection{Methods}
To further investigate the behavior implied by Lemmas 1, 2 and 3 a benchmark was conducted.
Using a single kmer-index for $k=10$, randomly generated queries of length $\{6,7,...,50\}$ were searched in a
randomly generated text and the search calls duration to return was measured.

% SINGLE KMER: RESULTS
\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_vs_single/single_only}

\caption{\label{figure 1}Average duration to get all occurences of a query
of given length using a kmer-index for $k=\{10\}$. The inset graph
shows a``zoomed in'' view of the area of query lengths $[16,29]$.
The dotted lines mark query lengths that are a multiples of $k$.}

\end{figure}

The results show a predictable pattern substantiating the above mentioned
lemmas. Best performance is only achieved for query sizes $m:\:m\mod k=0$
as this avoids having to search a rest with \lstinline{search_subk}.
While queries of length $(n*k)-1,\,(n*k)-2:\:n\in\{1,2,...\}$ still
show acceptable performance, as the absolute difference between $m$
and $k$ increases the performance becomes worse (in accordance with
Lemma \ref{Lemma 2}). For queries of length $m=(n*k)+1$ results suggest
a runtime increase of up to $6{{}^7}\approx280\,000$ times compared
to best-case performance. Note that the peaks at $(n*k)+1$ reduce
in severity as query length increases. This is because with an increase
in query length given a text of fixed size the number of results per
query decreases and as stated in Lemma \ref{Lemma 3} performance will
improve slightly.

% MULTI KMER: METHODS
\section{Multi kmer-Index}
\subsection{Methods}
Given this behavior of the single kmer-index if we want to choose more $k$ to improve average
performance the most obvious addition would be to cover the previous $k$s
worst case performance: for example for $k_{1}=10$ we would additionally
choose $k_{2}=k_{1}+1=11$, $k_{3}=k_{2}+1$ and so on. Ideally we would
just use every possible $k$ in one multi kmer-index however due to memory limitations
this is sometimes not feasible. As observed above, runtime for query length $m=k-1$
was still satisfactory and thus $k_{i}=\{5,7,9,...,27,29,31\}$ was
chosen as a substitute to a multi kmer-index with perfect coverage. It was again constructed
over a randomized text and the search functions time to return all occurences of a randomized kmer with
fixed length was measured and compared to the results for the single kmer-index above.

% MULTI KMER: RESULTS
\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_vs_single/multi_vs_single}
\label{single_vs_multi}
\caption{Average search performance of multi and single kmer-index to find
all occurrences of a query of given length in a text of size $10^{6}$.}
\end{figure}

Despite the suboptimal coverage of the multi kmer-index performance is still very close to optimal. Note that at query
length 10 the single kmer-index shows faster performance than the multi kmer-index (c.f. red vertical line in figure 2.3).
This illustrates the slight difference in runtime between $k=m$ (which is the case for the single kmer-index
at $m=10$) and $k=m+1$ (which is true for the multi kmer-index) as it was provided $k=11$).
Note further how after $m=33$ runtime increases significantly. To explain this we need to investigate how the
multi kmer-index handles queries that cannot optimally be search using only a single k more closely.

% MULTI KMER: HOW TO CHOOSE K
\subsection{How to choose the appropriate k}
As demonstrated above the success of the multi kmer-inde to perform well relies heavily on both being provided the
approriate $k$ and choosing which $k$s to use for a certain query length. The latter is provided
by a table that computes for every possible query length $m$ a set of$\{k_{a},k_{b},...\}$
such that $k_{a}+k_{b}+...=m$. To achieve best performance we want
the minimal set (in regards to cardinality) of $k_{i}$ and for each of the $k_{i}$ to be chosen as big as possible which
in accordance with Lemma\ref{Lemma 3} reduces runtime for longer queries. This table is constructed with a simple
dynamic programming approach where to find the set of $k_{i}$ for a given query $m_{j}$ the already computed
set for a queries $m_{a},m_{b}<m_{j}:m_{a}+m_{b}=m_{j}$ are unified to create the new set.

\begin{table}[H]
\centering{}\caption{Set of $k_{i}$ for certain query lengths chosen from $k\in\{9,11,13,17\}$
by the multi kmer-index.}
\begin{tabular}{cc}
\toprule
query length & summands\tabularnewline
\midrule
\midrule
29 & 9+9+11\tabularnewline
\midrule
30 & 13+17\tabularnewline
\midrule
31 & 9+9+13\tabularnewline
\midrule
32 & n/a\tabularnewline
\midrule
33 & 9+11+13\tabularnewline
\bottomrule
\end{tabular}
\end{table}

Depending on the set of $k_{i}$ supplied at construction, not all query lengths may
be possible to be represented with only the supplied summands. In this
case the kmer index falls back on calling \lstinline{search_subk}
for one of the summands. To find a set of$k_{i}$ that covers most
of the queries supplied by the user, the following recommendations
should be kept in mind:

\begin{itemize}
\item no $k_{i}$ should be a multiple of another such that $\lnot\exists k_{j}:k_{i}\mod k_{j}=0$.
This is to avoid redundancy as the higher $k_{i}$will always be chosen
\item all $k_{i}$ should be as big as possible as stated above.
\item small $k_{i}$ should be avoided completey. If $k_{1}=3$ is provided
and is used for a sum, the index will have to crossreference all results
for a single 3mer which depending on the texts length may be far slower
than just searching that query with \lstinline{search_subk}. Initial
results suggest to not use any $k_{i}<10$. While they can still be supplied
the index will not use them for searching queries of bigger lengths unless unavoidable.
\end{itemize}
The author recommends for the set of $k_{i}$ to be a subset of \{9,
11, 13, 17, 19, 21, 23, 27, 29, 31\}, primes are preferable because
most queries will be able to be factorized into a subset of them.
For example $\{11,13,17,19,21\}$ will cover every query length $31<m\leq10000$
and the $k$ are small enough to be stored on less capable machines
even with bigger texts such as an entire genome. Note that if searching
for occurences of queries of length $m\in[3,31]$ the query length
should be directly supplied to the set of $k_{i}$ as a length smaller
than $min(ks)$ cannot be represented as a sum of$k_{i}$s.

Given this information we can now explain the harsh increase at $m=35$ in \ref{single_vs_multi}: For $m=33$ the index
divides the query into 3 search calls with $k=11$. For $m=34$ it will use $k=15, 19$ which both perform adequately.
For $m=35$ no such sum exists with the given $k$s so the index has to fall back to using the slower \lstinline{search_subk}
which increases runtime significantly.

\section{Comparison with fm\_index}
\subsection{Methods}
To put the absolute runtime durations of the above figures into perspective a comparative analysis
of seqan3s \lstinline{fm_index}\footnote{Note that for exact string matching there is is no relevant performance
difference between the fm- and bi-fm-index.} and the multi kmer-index runtime was conducted. Both indices were
constructed over the same randomized text and queried with the same set of randomized queries. The measured runtime was
converted into relative speedup as such:

\begin{verse}
let $t_{fm<i>},t_{kmer<i>}$ the search runtime for searching a query
of length$i$ with the corresponding index

then $\text{{speedup}}(i)=\begin{cases}
+(1-(t_{kmer<i>}/t_{fm<i>})) & \text{{if}\;}t_{kmer<i>}>t_{fm<i>}\\
-(1-(t_{fm<i>}/t_{kmer<i>})) & \text{{if}\;}t_{kmer<i>}<t_{fm<i>}\\
\,0 & \text{{else}}
\end{cases}$|
\footnote{To clarify, if $\text{speedup}(a,b)=+75\%$ the $b$ has a runtime of 1.75 the runtime of $a$, that is $a$ is 75\% faster than $b$.}
\end{verse}

\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/just_k/relative_speedup}

\caption{Relative speedup (in \%) for search calls of the kmer-index vs. the
fm-index per query length with a text size of $10{{}^8}$. The inset
plot shows the absolute runtime (in ns). The multi kmer-index used $k\in$
\{3, 4, ..., 9, 10, 11, 12, ..., 31\}}
\end{figure}

Results indicate that for bigger texts the kmer index will only perform
better for relatively small $k$. This is because the indices map is
limited to a size of $\sigma^{k}$ and as the kmer indices runtime
for searching a single kmer is indepent from the number of results
for that query, for bigger text higher $k$ will vastly increase the
maps size and thus the time it takes to traverse it. For sufficiently
small texts however, all $k\in\{3,30\}$ will be faster to search and
the overall speedup for short queries like these suggests that the
kmer index should be preferred to search small kmers.

\begin{table}[H]
\noindent \raggedright{}\caption{\label{table kmer faster while}Average$speedup(t_{kmer},t_{fm})$
in the interval$[3,30]$ per text length. Results rounded to 1 decimal
digit to account for noise in benchmark results.}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}}>{\centering}p{0.15\textwidth}>{\raggedleft}p{0.1\textwidth}>{\raggedleft}p{0.15\textwidth}>{\raggedleft}p{0.15\textwidth}>{\centering}p{0.25\textwidth}}
\toprule
text size & mean & maximum & mininum & kmer faster while\tabularnewline
\midrule
\midrule
$10{{}^3}$ & 21\% & 64.9\% & 3.0\% & k < 31\tabularnewline
\midrule
$10{{}^4}$ & 19.3\% & 64.2\% & 2.2\% & k < 31\tabularnewline
\midrule
$10{{}^5}$ & 17.3\% & 65.7\% & 0.4\% & k < 31\tabularnewline
\midrule
$10{{}^6}$ & 16.7\% & 58.8\% & 2.0\% & k < 31\tabularnewline
\midrule
$10{{}^7}$ & 9.4\% & 54.5\% & -4.6\% & k < 22\tabularnewline
\midrule
$10{{}^8}$ & 8.2\% & 62.1\% & -11.3\% & k < 17\tabularnewline
\midrule
$10{{}^9}$ & < 7\% & 48.9\% & < -16.5\% & k < 11\tabularnewline
\bottomrule
\end{tabular*}
\end{table}

While in praxis searching queries of size $m<31$ may find use when for example developing and working with kmer spectra \cite{kmer:spectrum:dissimilarity}
as a way of classification, in the application of read-mapping reads are
\href{https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/read-length.html}{rarely shorter than $m=50$}
and in other applications query lengths may go far beyond that. To investigate the kmer-index performance in these cases
the same methods noted above were applied to queries of arbitrarily long sequences.

\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_kmer_vs_fm/5_1000/runtime_diff_over_text_size}\caption{\label{figure 5_100}
Graphs showing $\text{speedup}(t_{kmer},t_{fm})$ over
query lengths for different text sizes. The grey area highlights query
lengths {[}5, 30{]} which were excluded when calculating the depicted median speedup per text length.
The multi kmer-index used all $k\in\{5, 6, 7, 8, 9, 10, 11, 12,
13, 15, 17, 19, 21, 23, 25, 27, 29, 31\}$.}
\end{figure}

\section{Discussion}
Overall the multi kmer-index has proved superior for searching appropriately small kmers as detailed in Table
\ref{table kmer faster while}. While more testing will need to be done to confirm this it seems reasonable to assume
that the multi kmer-index will always perform better than seqan3s fm\_index for query of length $m<10$. Queries this small
rarely see application in praxis however depending on text size the multi kmer-index may
exhibit overall speedup compared to the fm\_index for arbitrary queries and is therefore recommend for use with text
under a certain sizes. More testing needs to be done to confirm this boundary but results presented here suggest
positive speedup is achieved for text length $n<1e+07$.



