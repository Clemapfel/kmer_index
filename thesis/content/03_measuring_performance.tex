%\chapter{Measuring Performance}
\chapter{Measuring Performance}

% UNORDERED MAP: METHODS
\begin{minipage}{\linewidth}
\section{Unordered Map}
\subsection{Methods}
Because an unordered map is the central data structure of the kmer-index choosing the best performing available
implementation contributes tremendously to the performance of the kmer-index. As C++s \lstinline{std::unordered_map}
did not prove sufficiently performant enough the following maps implemented by 3rd parties were additionally tested and evaluated
specifically in the context of use within the kmer-index:

\begin{itemize}
\item \lstinline{std::unordered_map} from the \href{https://en.cppreference.com/w/cpp/container/unordered_map}{C++17 standard library}
\item \lstinline{boost::unordered_map} from the \href{https://www.boost.org/doc/libs/1_65_0/doc/html/boost/unordered_map.html}{1.65.1 Boost Library}
\item \lstinline{absl::node_hash_map} from Googles \href{https://abseil.io/docs/cpp/guides/container\#abslnode_hash_map-and-abslnode_hash_set}{Abseil}
\item \lstinline{robin_hood::unordered_map} as provided by \href{https://github.com/martinus/robin-hood-hashing}{Martin Ankerl et. al.}
\end{itemize}

Each map was filled with a fixed number of randomized integers simulating both the hash and position of kmer in the
final implementation and the duration to return a specific element when provided a randomized key was measured.
Only retrieval was tested here because after construction of the kmer-index no insertions will take place.

% UNORDERED MAP: RESULTS
\subsection{Results}
\begin{figure}[H] \label{}
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/map_vs_map/map_vs_map}

\caption{Search performance for different map implementations over size of
map.}
\end{figure}
\end{minipage}

Results indicate that \lstinline{robin_hood::unordered_map} performed
best regardless of the number of elements contained and was as such
used as the central data structure for the kmer-index.

% SINGLE KMER: METHODS
\section{Single kmer-Index}
\subsection{Methods}
To further investigate the behavior implied by Lemmas 1, 2 and 3 a benchmark was conducted.
Using a single kmer-index for $k=10$ randomly generated queries of length $\{6,7,...,50\}$ were searched in a
randomly generated text and the search calls duration to return was measured.

% SINGLE KMER: RESULTS
\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_vs_single/single_only}

\caption{\label{figure 1} Average duration of searching a query of given length.
The dotted lines designate query lengths that are a multiple of $k$.}
\end{figure}

The results show a predictable pattern substantiating the above mentioned
lemmas. Best performance is only achieved for query sizes $m:\:m\mod k=0$
as this avoids having to search a rest with \lstinline{search_subk}.
While queries of length $(n*k)-1,\,(n*k)-2:\:n\in\{1,2,...\}$ still
show acceptable performance, as the absolute difference between $m$
and $k$ increases the performance becomes worse (in accordance with
Lemma \ref{Lemma 2}). For queries of length $m=(n*k)+1$ results suggest
a runtime increase of up to $6{{}^7}\approx280\,000$ times compared
to best-case performance. Note that the peaks at $(n*k)+1$ reduce
in severity as query length increases. This is because with an increase
in query length given a text of fixed size the number of results per
query decreases and as stated in Lemma \ref{Lemma 3} performance will
improve slightly.

% MULTI KMER: METHODS
\section{Multi kmer-Index}
\subsection{Methods}
Based on the exhibited behavior of the single kmer-index if we were to pick additional
$k$ to increase performance, the most obvious addition would be to cover the previous $k$s
worst cases: for example for $k_{1}=10$ we would additionally
choose $k_{2}=k_{1}+1=11$, $k_{3}=k_{2}+1$ and so on. Ideally we would
just use every possible $k$ in one multi kmer-index however due to memory limitations
this is sometimes not feasible. As observed above, runtime for query length $m=k-1$
was still satisfactory and thus $k_{i}=\{5,7,9,...,27,29,31\}$ was
chosen as a substitute to a multi kmer-index with perfect coverage. It was again constructed
over a randomized text and the search functions time to return all occurences of a randomized kmer with
given length was measured and compared to the results for the single kmer-index above.

% MULTI KMER: RESULTS
\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_vs_single/multi_vs_single}
\label{single_vs_multi}
\caption{Average search performance of multi and single kmer-index to find
all occurrences of a query of given length.}
\end{figure}

Despite the suboptimal coverage of the multi kmer-index performance is still very close to optimal. Note that at query
length 10 the single kmer-index exhibits better performance than the multi kmer-index (c.f. red vertical line in figure \ref{single_vs_multi}).
This illustrates the slight difference in runtime between $k=m$ (which is the case for the single kmer-index
at $m=10$) and $k=m+1$ (which is true for the multi kmer-index) as it was provided $k=11$ instead.
Note further how after $m=33$ runtime increases significantly. To explain this we need to investigate how the
multi kmer-index handles queries that cannot optimally be search using only a single $k$ more closely.

% MULTI KMER: HOW TO CHOOSE K
\subsection{How to choose the appropriate k}
As demonstrated above the success of the multi kmer-index to perform well relies heavily on both being provided the
approriate $k$ and choosing which $k$s to use for a certain query length. The latter is achieved
via a table that computes for every possible query length $m$ a set of$\{k_{0},k_{1},...\}$
such that $k_{0}+k_{1}+...=m$. To achieve best performance we want
the minimal set (in regards to cardinality) of $k_{i}$ and it is desirable for each of the $k_{i}$ to be furthermore chosen
as big as possible which in accordance with Lemma \ref{Lemma 3} reduces runtime for longer queries. This table is constructed with a simple
dynamic programming approach where to find the set of $k_{i}$ for a given query $m_{j}$ the already computed
set for a queries $m_{a},m_{b}<m_{j}:m_{a}+m_{b}=m_{j}$ are unified to create the new set.

\begin{table}[H]
\centering{}\caption{Set of $k_{i}$ for given query lengths chosen from $k\in\{9,11,13,17\}$
by the multi kmer-index.}
\begin{tabular}{cc}
\toprule
query length & summands\tabularnewline
\midrule
\midrule
29 & 9+9+11\tabularnewline
\midrule
30 & 13+17\tabularnewline
\midrule
31 & 9+9+13\tabularnewline
\midrule
32 & n/a\tabularnewline
\midrule
33 & 9+11+13\tabularnewline
\bottomrule
\end{tabular}
\end{table}

Depending on the set of $k_{i}$ supplied at construction, not all query lengths may
be possible to be represented with only the supplied summands. In this
case the kmer index falls back on calling \lstinline{search_subk}
for one of the summands.\pagebreak\newline
To find a set of $k_{i}$ that covers most
of the queries supplied by the user, the following recommendations
should be kept in mind:

\begin{itemize}
\item no $k_{i}$ should be a multiple of another: $\lnot\exists k_{j}:k_{i}\mod k_{j}=0$.
This is to avoid redundancy as the higher $k_{i}$ will always be chosen.
\item all $k_{i}$ should be as big as possible.
\item small $k_{i}$ should be avoided completey. If $k_{1}=3$ is provided
and is used for a sum, the index will have to crossreference positions of occurences of a single
3mer (c.f. Section \ref{m > k}) which depending on the texts length may be far slower
than just searching the query with \lstinline{search_subk}. Initial
results suggest to not use any $k_{i}<10$. While they can still be supplied
the index will not use them for searching queries of bigger lengths unless unavoidable.
\end{itemize}
The author recommends for the set of $k_{i}$ to be a subset of \{9,
11, 13, 17, 19, 21, 23, 27, 29, 31\}\footnote{We are limited to $k\leq31$ as the entirety of the hashspace for $k\geq32$ cannot be represented with a single 64-bit unsigned integer}, primes are preferable because
most queries will be able to be factorized into a subset of them.
For example $\{11,13,17,19,21\}$ will cover every query length $31<m\leq10000$, that is no
query in that range will need to be searched with \lstinline{search_subk}
and the $k$ are small enough to be stored on less capable machines
even with bigger texts such as an entire genome.\newline Note that if searching
for occurences of queries of length $m\in[3,31]$ the query length
should be directly supplied to the set of $k_{i}$ because for a query length $m < min(ks)$
there is no combination of $k_{i}$ such that $\sum k_{i} = m$ and thus the index will have to
fall back to the possible worse performing \lstinline{search_subk}.

Given this information we can now explain the harsh increase at $m=35$ in Figure \ref{single_vs_multi}:
\footnote{Recall that the kmer-index is using $k_{i}\in\{5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31\}$}
For $m=33$ the index divides the query into three search calls using $k=11$ resulting in acceptable performance. For $m=34$ it will pick $k=15, 19$ also resulting in good performance,
however for $m=35$ it will have to choose to search seven 5-mers and crossreference their numerous positions resulting
in (as outlined in the recommendations above) worse performance.

\section{Comparison with fm\_index}
\subsection{Methods}
To put the absolute runtime durations of the previous figures into perspective a comparative analysis
of Seqan3s fm\_index and the multi kmer-index runtime was conducted. Both indices were
constructed over the same randomized text and queried with the same set of randomized queries. \newpage
The measured runtime was converted into relative speedup as such:

\begin{verse}
let $t_{fm<i>},t_{kmer<i>}$ the search runtime for searching a query
of length $i$ with the corresponding index

then $\text{{speedup}}(i)=
\begin{cases}
+(1-(t_{kmer<i>}/t_{fm<i>})) & \text{{if}\;}t_{kmer<i>}>t_{fm<i>}\\
-(1-(t_{fm<i>}/t_{kmer<i>})) & \text{{if}\;}t_{kmer<i>}<t_{fm<i>}\\
\,0 & \text{{else}}
\end{cases}$
\end{verse}

\subsection{Results}
\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/just_k/relative_speedup}

\caption{\label{speedup to 30} Relative speedup (in \%) for search calls using the kmer-index and
fm-index respectively per query length with a text size of $10{{}^8}$. The inset
plot shows the absolute runtime (in ns). The multi kmer-index used $k_{i}\in{5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31}$}.
\end{figure}
\begin{table}[H]
\noindent \raggedright{}\caption{\label{table kmer faster while} Average$speedup(t_{kmer},t_{fm})$
in the interval$[3,30]$ per text length. Results rounded to 1 decimal
digit to account for noise in benchmark results.}
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}}>{\centering}p{0.15\textwidth}>{\raggedleft}p{0.1\textwidth}>{\raggedleft}p{0.15\textwidth}>{\raggedleft}p{0.15\textwidth}>{\centering}p{0.25\textwidth}}
\toprule
text size & mean & maximum & mininum & kmer faster while\tabularnewline
\midrule
\midrule
$10{{}^3}$ & 21\% & 64.9\% & 3.0\% & k < 31\tabularnewline
\midrule
$10{{}^4}$ & 19.3\% & 64.2\% & 2.2\% & k < 31\tabularnewline
\midrule
$10{{}^5}$ & 17.3\% & 65.7\% & 0.4\% & k < 31\tabularnewline
\midrule
$10{{}^6}$ & 16.7\% & 58.8\% & 2.0\% & k < 31\tabularnewline
\midrule
$10{{}^7}$ & 9.4\% & 54.5\% & -4.6\% & k < 22\tabularnewline
\midrule
$10{{}^8}$ & 8.2\% & 62.1\% & -11.3\% & k < 17\tabularnewline
\midrule
$10{{}^9}$ & < 7\% & 48.9\% & < -16.5\% & k < 11\tabularnewline
\bottomrule
\end{tabular*}
\end{table}
Results indicate that for bigger texts the kmer-index will only perform
better for relatively small $k$. This is because the indices map will never have more than
$\sigma^{k}$ entries, this means for smaller $k$ the maximum map size (and thus map traversal runtime)
is reached even for smaller texts. As $k$ increases the kmer-indices map increases in
size dramatically resulting in worse performance.
For sufficiently small texts it is reasonable to assume that all $k\in\{3,30\}$ will be searched faster than
with the fm\_index\footnote{Note that for exact string matching there is is no relevant performance
difference between the fm- and bi-fm-index.} and as such results suggest that preferring the kmer-index in these applications is recommended.\linebreak
While in praxis searching queries of size $m<31$ may find use when for example developing and working with kmer spectra
(Dubinkina et. al. decided to employ kmer spectra for $k\in[5, 11]$ \cite{kmer:spectrum:dissimilarity}),
in the application of read-mapping reads are
\href{https://www.illumina.com/science/technology/next-generation-sequencing/plan-experiments/read-length.html}{rarely shorter than $m=50$}
and in other applications query lengths may go far beyond that. To investigate the kmer-indices performance in these cases
the same methods used above were applied to queries of arbitrary length. \newpage

\begin{figure}[H]
\includegraphics[width=1\textwidth]{/home/clem/Workspace/kmer_index/source/benchmarks/multi_kmer_vs_fm/5_1000/runtime_diff_over_text_size}\caption{\label{figure 5_100}
Graphs showing relative $\text{speedup}(t_{kmer},t_{fm})$ over
query lengths for different text sizes. The grey area highlights query
lengths $[5, 30]$ which were excluded when calculating the depicted median speedup per text length. The results in Figure
\ref{speedup to 30} where taken from the same benchmark run as these.}
\end{figure}

\section{Discussion}
Overall the multi kmer-index has proved superior for searching appropriately small kmers as detailed in Table
\ref{table kmer faster while}. While more testing will need to be done to confirm this, it seems reasonable to assume
that the multi kmer-index will always perform better than Seqan3s fm\_index for query of length $m<10$. Queries this small
rarely see application in praxis however depending on text size the multi kmer-index may
exhibit overall speedup compared to the fm\_index for longer queries and is therefore recommend for use with text sizes
under a certain threshold. More testing needs to be done to confirm this boundary but results presented here suggest
overall positive speedup is achieved for text length $n<10^{7}$.


